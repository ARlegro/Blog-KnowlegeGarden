---
{"dg-publish":true,"permalink":"/Computer_Science/Virtual_Memory/Virtual Memory/","noteIcon":"","created":"2025-07-13T17:00:57.171+09:00","updated":"2025-08-21T15:21:20.800+09:00"}
---

#메모리_관리_기법 

**Preview**
- 실제 물리적 메모리보다 더 큰 메모리를 사용하는 것**처럼 보이게 하는** 메모리 관리 기법 
- HDD공간을 메모리처럼 활용하여 프로그램이 마치 실제 메모리가 충분한 것처럼 작동 
- (프로세스가 독점적으로 사용하는 것처럼 메모리 가상화)

>[!EXAMPLE] Window 시스템에서 메모리 운용 3가지 방법
>1. **가상 메모리** 시스템 활용
>2. 메모리 맵
>3. 힙 


---
## 0. 도입 

---
### 가상 메모리기법❓

> 컴퓨터 시스템이 실제 물리적 메모리(RAM)보다 훨씬 더 큰 메모리를 사용하는 것**처럼 보이게 하는** 기술 (By HDD공간을 RAM처럼 사용)

---
### 가상 메모리란 ❓
#메모리_추상화

 OS는 프로세스, 가상 메모리, 파일 을 통해 추상화를 달성했다.
![Pasted image 20250713133447.png](/img/user/supporter/image/Pasted%20image%2020250713133447.png)
---
#### 개념과 효과

*✔개념* 

> OS와 H/W가 상호작용하여 프로세스마다 독립적인 메모리 공간을 제공하는 기법 

- *메모리를 추상화*하여 **각 프로세스에게 독립적인 메모리 공간을 제공**
	- OS는 각 프로세스에게 독립된 가상 메모리 공간을 준다
- 이러한 기법은 CPU, 메모리, 디스크, 커널이 *유기적으로 상호작용함으로써 프로세스가 실제 공간보다 더 큰 공간을 가진 것처럼 보이게* 함 
- 예를 들어, 32bit 운영체제에서 OS가 어떤 프로세스에게 32bit 공간(4GB)을 준다면 그 프로세스는 그 범위 내에서 메모리 사용 
		
>[!QUESTION] 근데, RAM은 보통 16GB인데 한 애플리케이션에 4GB나❓
>- 이건 말이 안 된다.
>- 즉, OS가 부여한 가상 메모리 주소는 **실제 RAM 용량과 무관**하게 각 프로세스에게 주어지는 **"논리적"인 공간**이다.
>- 이로 인해, RAM이 16GB여도 64bit 애플리케이션 여러개를 동시에 실행할 수 있다.


*✔효과* 
>[!tip] 목적 : 메모리를 더 효율적이고 에러 발생을 줄이기 위해 

1. *메모리 효율성*
	- **필요한 Page만 RAM에** 올린다. 
	- 이로 인해,
		1. **초기 로드 시간이 감소**하고 
		2. 여러 프로세스/데이터를 **동시에 다룰 수** 있어짐 (실제 RAM 용량보다 더)
	  
2. *프로세스 보호*
	- 각 프로세스의 주소 공간을 다른 프로세스에게 침범받지 않음 
	- 각 프로세스는 자신만의 Page Table을 가진다 ➡ **다른 프로세스의 메모리를 읽거나 쓸 수 없음 ✅(버그 발생 차단)**
	  
3. *메모리 관리 간소화*
	- **모든 프로세스에게 균일한 주소공간을 제공**하기에 단순화됨 
		- 가상 주소와 매핑될 **실제 메모리 주소는 외부 파편화**되어 있는데 **가상 주소는 연속된 주소**로 되어 있기에 프로세스는 연속된 주소로 가정하고 코드 진행 가능 
	- 그 외 이유 많은데 너무 딥해서 Pass


>[!EXAMPLE] 필요성 대두 : 가상 메모리 없었던 옛날 애기 
>1. **부족한 메모리 사용 공간**
>	- RAM 공간이 각 프로세스 전부 담기에는 부족 
>	- 주어진 RAM이상의 메모리를 사용하려고 하면 프로그램 충돌 발생 
>	  
>2. **메모리 단편화로 공간 활용 비효율적** 
>	![Pasted image 20250818171038.png](/img/user/supporter/image/Pasted%20image%2020250818171038.png)
>	- 총 공간은 충분한데 실행 못했던 시절 Cuz 단편화로 인해
>	  
>3. **안정성/보안 문제**
>	- 다른 프로세스가 같은 메모리에 접근하려 시도 시 문제 발생 



---
## 1. 주소 방식을 통한 문제 해결 
> 어떻게 가상 방식이 기존 방식의 문제를 해결했는지

---
### 사전 개념 : 물리 주소 vs 가상 주소 

> 가상 메모리 주소 방식은 여러 문제들을 해결해줬다. 그 과정 설명 전에 물리 vs 가상 주소 방식의 차이를 공부 ㄱ
> 1. 옛날 방식
> 2. 가상 방식

개념 정리
- 가상 주소(VA) : 프로세스가 보는 주소 
- 물리 주소(PA) : DRAM이 실제로 가진 위치 
- MM = Main Memory
- RAM ➡ 물리적 메모리
- RAM 주소 ➡ 물리적 주소(PA)
- **⭐Note : 다른 메모리 or 레지스터 주소 공간에도

---
#### 1. 물리 주소 방식(옛날)
![Pasted image 20250818190748.png](/img/user/supporter/image/Pasted%20image%2020250818190748.png)
>CPU가 메인 메모리의 물리 주소(PA)를 사용
- *PA : 각 Byte의 고유 주소인데 물리적으로 존재*

>[!EXAMPLE] 물리 주소 시스템 흐름
>1. *CPU의 Load Instruction 실행*
>	- 메모리에서 데이터를 읽어오라는 명령어 
>2. *유효 주소를 계산*
>	- 주체 : CPU 내부의 주소 계산 유닛(AGU)
>	- 이때는 이 결과가 물리주소
>	  
>3. *주소를 주소 버스를 통해 전달*
>	- CPU는 **2번에서 계산한 주소를** Address Bus를 통해 **메인 메모리(MM)에 전달** 
>	- 이 때, 6장에서 배운 내용대로 Control Bus에 읽기 신호도 보냄 
>	
>4. *MM은 3번에서 전달받은 위치의 데이터를 읽고, CPU에 전달*
>	- CPU에 의해 계산된 **주소 값을 보고**,
>	- 그 주소에 해당하는 **셀의 데이터를 읽어,**
>	- Data Bus에 **적재 후 CPU에 전달** 
>	  
>5. *CPU는 4번에서 받은 값을 받아 레지스터에 저장* 

=> 나중에 E.D로 만들어보기 

❌현대의 대부분 프로세스들은 이 방법을 안 씀 (이유는 위에서 언급한 가상메모리 내용 참고)


---
#### 2. 가상 주소 방식 (多)
![Pasted image 20250818191111.png](/img/user/supporter/image/Pasted%20image%2020250818191111.png)

***✔가상 주소 시스템 흐름***(생성하는 과정)
> 가정 : 캐시 및 TLB에 가상 주소가 없다고 가정 
1. CPU의 *Load Instruction 실행* (데이터 읽어오기 시작)
2. *가상 주소(VA) 계산* by AGU(주소 생성 유닛)
3. TLB 및 캐시에 *있는지 확인*(뒤에서 나오니 지금 알 필요 X)
4. 가상 주소(VA) *생성*
5. 물리 주소(PA)로 *변환* (**주소 번역**)
	- 이 과정에서 **OS가 관리하는 참조 테이블**과 **CPU H/W를 활용**해야 함
	- **참조 테이블** : PA와 VA를 매핑해주는 역할. MM에 저장된 테이블로, OS가 관리
	- **MMU** : CPU 내 메모리 관리 유닛으로 **참조 테이블을 번역**한다. 또한 **가상 주소를 물리 주소로 변환해주는 역할**도 한다
	  
6. 이후 과정은 물리 주소 방식의 방식과 동일


>[!example] 가상 주소(VA) 구조 = (P, D)
>- P : Page Number(페이지 번호)
>- D : Offset (오프셋, 거리) - 페이지(프레임) 첫 번째부터 얼마나 떨어져 있는지
![Pasted image 20250730191155.png](/img/user/supporter/image/Pasted%20image%2020250730191155.png)


> [!INFO] SRAM 캐시 사용하는 시스템에서는 가상 주소(VA)를 잘 사용하지 않으려 함 
> 초고속 접근을 위해 **주소 변환 과정을 건너뛰고 물리 주소를 직접 사용**. 이유는 아래와 같다
> 1. *큰 메모리가 필요 없음* 
> 	- 대부분의 캐시는 작은 용량임 (큰 용량이 필요 없기 때문)
> 	- 그래서 가상 메모리의 장점인 메모리 크기를 따를 필요 없음 
> 	  
> 2. *보호 불필요*
> 	- 보통 캐시는 데이터를 수정하지 않는다.(업데이트 말고)
> 	- 대부분 캐쉬는 저장/검색 위주로 사용
> 	  
> 이런 것들이 필요 없으니 단순화해서 회로 크기, 전력, 설계 난이도를 줄임 


---

### 해결 1. 메모리 부족 해결 - 가상 주소 방식의 Swapping
>[!QUESTION] 문제 상황 : 매핑 과정에서 실제 RAM 공간보다 더 많은 데이터에 접근하려고 하면?
>- 당장 급하지 않은 데이터를 다른 곳에 저장!!(ex. HDD, SSD) By OS

> 가상 메모리의 진짜 주소는 RAM일수도 HDD일수도 (이건 OS의 메모리 매니저가 해줌)

![Pasted image 20250813133317.png](/img/user/supporter/image/Pasted%20image%2020250813133317.png)
1. *RAM초과 상태에서 저장 시 - 다른 위치로(HDD) 저장*
	- RAM보다 더 많은 데이터를 저장하려 하면 OS 다른 곳에 저장할 수 있다.
	- 즉, **디스크를 추가 메모리로 사용하는 것** 
	- **스왑 메모리** = 가상메모리 과정에서 **디스크에 추가로 사용한 메모리** 
	  
2. *데이터 조회 시 - HDD에 있는 상황*
	- OS는 HDD에 데이터가 있다는 것을 **알리고,**
	- RAM에 **가장 오래된 데이터를 디스크로 옮기고,**
	- **조회하는 데이터 주소를 RAM으로 옮긴다.**
	- 이후, **매핑 정보도 최신화** 시킴 
	- Note : 이런 과정을 Page Fault라 함(뒤에서 자세히 적을 것)


>[!tip]  참고 : RAM의 일부는 OS전용 공간이 따로 있음 
![Pasted image 20250818171859.png](/img/user/supporter/image/Pasted%20image%2020250818171859.png)



---
### 해결 2. 단편화 문제 해결 - 속임수로 

#### 문제 상황
![Pasted image 20250818171038.png](/img/user/supporter/image/Pasted%20image%2020250818171038.png)
- 물리적 메모리 용량은 충분한데 연속된 큰 공간이 부족해서 프로그램을 Load하지 못하는 상황
- **프로그램의 실행 조건 : 연속된 주소 공간 요구 ⭐**

#### 가상 주소의 속임수 
> 프로그램이 연속 가상 주소 공간 요청 ➡가상 주소 공간에서 연속된 주소 확보 
- *실제 물리 메모리*에는 **조각된 공간을 매핑**하지만,
- *프로그램 입장*에서는 **연속적으로 주소 공간이 배치되어 있어 보이기에** 실행 조건이 맞은 것 
- 이렇게 하면 실제 메모리의 **외부 단편화 문제도 해결**되어 **효율적인 메모리 관리 가능** 


>[!QUESTION] 외부 단편화란?
>- 메모리 공간에 여러 블록들을 임의로 막 배열하다보면 자잘자잘하게 남는 공간들이 생길 것이다.
>- 이로 인해 **총 메모리 용량은 충분하지만, 연속적인 큰 블록이 없어서 새로운 프로세스를 수용할 수 없는 현상**이 발생.

#### 단편화 된 것을 재조립 
> 가상 메모리의 페이징 기법은 외부 단편화를 발생시키지 않는다.

*페이징의 해결 방식*
- 메모리를 고정된 크기로 나눠 논리적인 부분은 단편화 시킨다.
- 물리 메모리에서는 작은 빈 공간들이 흩어져 있어도 이를 **재조합하여 프레임단위로 만들고 프로그램 실행**한다 Cuz 프로세스는 연속된 공간을 요구하지 않기 때문 
![Pasted image 20250819190148.png](/img/user/supporter/image/Pasted%20image%2020250819190148.png)


### 해결 3. 안정성/보안 문제 해결 

#### 해결 방식 
> 각 프로세스는 독립된 가상 주소 공간과 독립된 매핑 테이블을 가진다.

![Pasted image 20250818202211.png](/img/user/supporter/image/Pasted%20image%2020250818202211.png)
- **각 프로세스 간에 메모리를 침범할 일이 없다.**
- *❓다른 매핑 테이블을 쓰더라도 결국 MM 접근 시 충돌 나지 않는가❓*
	- 애초에 OS는 **같은 물리 주소를 다른 프로세스에게 배정하지 않게 설계되어** 있다.

> [!WARNING] 완벽한 분리는 아니다
> - 의도적으로 프로세스간 데이터를 공유하려고 같은 물리 주소로 변환시키기도 함  ex. 공유 라이브러리


#### 참고 : 커널 영역 가상 메모리 일부는 하나를 가리킴 
>⭐사실 모든 프로세스에게 부여된 Kernel 영역 가상 메모리의 일부는 **실제로는 하나이다**

![Pasted image 20250813131433.png](/img/user/supporter/image/Pasted%20image%2020250813131433.png)
- 모든 프로세스에게 독립적으로 부여된 **가상메모리의 커널 영역 중 일부**는... 사실 그 메모리는 실제 공간 하나를 가리킨다.
- "가상 메모리는 선형적이다"말의 의미는❓메모리가 연속적인 배열 형태로 되어 있다는 뜻(논리적으로) 	ex. *4GB 배열 -> char[43억]*
- **32bit 어플리케이션 ➡ 4GB만큼 배열 메모리처럼 생긴 가상 메모리가 주어짐**(64bit는 16EB로 4GB보다 43억배?? - 1bit 당 주소공간 2배 늘어남 - $2^{32}$)


---
#### 참고 : 4GB는 너 것이 아니다 💢
> 한 애플리케이션에 부여된 4GB의 가상 메모리 공간 전체는 사용자가 쓸 수 있는 곳은 아니다!! 
- 보통 사용자 영역과, Kernal 영역을 2GB씩 파티셔닝한다 
- User가 Kernal영역에 직접 접근하려고 하면 애플리케이션은 강제 종료된다.(User 영역을 거쳐야)
- 심지어 User영역의 일부는 OS 전용 공간
![Pasted image 20250729134400.png](/img/user/supporter/image/Pasted%20image%2020250729134400.png)

---
### 심화 : 커널 영역 
정리 자료 : [[Computer_Science/Memory_Hierarchy/커널 영역 심화\|커널 영역 심화]]


---
### 추가 효과 : 단순화 
> 2번에서 배우는 페이징 방법 + 가상 주소 방식은 **메모리가 시스템에서 사용되고 관리되는 방식에 중요한 영향**을 미침 
> - 링킹 과정에 단순화
> - 로딩 과정에 단순화
> - 코드/데이터 공유 단순화
> - 메모리 할당 단순화 <<< 나중 `malloc()`과 연관

---
#### 1. 링킹 단순화 
#고정된주소에맞춰
> 가상 메모리는 각 프로세스에 일관되고 균일한 주소 공간을 제공 
- 실제 메모리 주소와 상관 없음
- 따라서 시스템은 *링커를 설계할 때 단순화* 가능(물리적 주소 고려 필요 없음)
	- **링커가** 작업할 때 **미리 정해진 틀 내에서 링킹 과정을 진행하도록** 설계하면 됨⭐
	- ex. Code Segment는 어디부터~, Data Segment는 어디부터~, 

---
#### 2. 로딩 단순화 

> 가상 메모리는 **실행 파일(`.O`)과 공유 객체 파일(`.SO`)을 메모리로 로드하는 과정을 단순화** 함 
> -> 데이터를 필요할 때마다 그 때 불러오는 **Lazy Loading** 

*Lazy Loading이란❓*
- 실행 파일을 2차 메모리(HDD, SSD)에서 메인 메모리(RAM)로 로드할 때, 파일에 해당하는 데이터를 전부 로딩하지 않고,
- **지금 당장 필요한 데이터들만 로드(복사)하는 방법**

>[!QUESTION] 어떻게 지연 로딩을 가능하게 했는가❓
>- 프로그램은 연속적으로 주소가 할당되어야 실행이 가능한데, 
>- 가상 메모리 시스템에서는 **해당 프로그램의 데이터를 가상 페이지에 전부 담을 수** 있다 
>	- 참고로, 이건 등록만 한 것이다.
>	- 매핑은 ❌ (접근 하려고 하면 TLB 미스 or Page Fault 발생 함 )
>- 대신, **실제 RAM에는 일부만 담김** 

>[!tip] 가상 메모리가 없었다면 이런 Lazy Loading 방법을 사용하지 못 했음 


---
#### 3. 공유 단순화 
#단일복사본공유 

> 공유 주소의 실제 주소는 하나!!

*서로 다른 가상 페이지... But 동일한 물리 페이지 접근*
- 각 프로세스 or 파일들은 **각자의 가상 테이블에 가상 주소 공간을 가지고** 있지만,
- 이 주소 공간을 링킹하면 **동일한 물리페이지로 매핑**하게 된다.
- 이 때, 실제로 **한 개의 주소만 공유하므로 메모리 절약** 가능 

---
#### 4. 메모리 할당 단순화 

> 물리적으로 연속된 공간을 할당하지 않아도 됨 
- 외부 단편화 문제 해결한 내용임
- 너무 간단한거라 Pass

---

## 2. 가상 메모리 페이징 

### 페이징 기법❓ 
> *가상 주소를 물리 주소로 매핑하는 메모리 관리 기법*
- **가상 메모리 주소 공간을** 고정된 크기인 "**페이지(Page)**" 단위로 쪼개고, 
- **물리 메모리**도 동일한 크기의 **프레임(Frame)** 단위로 나누어 
- 가상 주소를 물리 주소로 매핑하는 메모리 관리 (보통 페이지, 프레임은 4KB로 동일하게 끊어준다 - 매핑 쉽게)
- ![Pasted image 20250730190220.png](/img/user/supporter/image/Pasted%20image%2020250730190220.png)
	- 이 배열에 stack, heap, 커널 코드 모두 그 안에 들어있음


### 페이지 테이블 
> 페이지 테이블이란? **논리 주소를 물리 주소로 매핑**하기 위해 사용하는 자료구조 

![Pasted image 20250730190522.png](/img/user/supporter/image/Pasted%20image%2020250730190522.png)
- 테이블은 여러 개의 "페이지 테이블 엔트리(PTE)"로 이루어져 있다.
- **페이지 단위로 매핑**한다(❌Word 단위❌)


>[!QUESTION] 페이지 테이블 엔트리(PTE)??
>- 페이지 테이블을 구성하는 각 항목 
>- 각 엔트리는 하나의 페이지에 대한 정보 담고 있음 ex. Frame번호, 유효 비트 등 

💢페이지 테이블은 크기가 매우 크다 Cuz 모든 페이지에 대한 정보 담고 있음. 그래서 이 문제를 해결하려고 **TLB**, MPT 등이 사용됨 

TLB는 뒤에서 배우니 나중에 공부 ㄱ 
(참고 : https://www.youtube.com/watch?v=A9WLYbE0p-I)


### Page Fault - 디스크로의 접근

> RAM에 찾고자 하는 데이터가 없을 때 발생하는 예외 

*Page Hit ↔ Page Fault*

#### 발생하는 상황 
*Page Fault 발생하기까지* 
1. **CPU는** 페이지 테이블에 **특정 페이지를 요청**한다
2. 페이지 테이블 엔트리를 보고 **그 데이터는 HDD(SDD)에 있다고 알린다.**
	![Pasted image 20250819000807.png](/img/user/supporter/image/Pasted%20image%2020250819000807.png)
3. **CPU는 예외를 터트린다** Cuz CPU는 그것을 읽는 방법을 몰름

➡ 이 때 발생하는 예외가 "**Page Fault**"

#### Page Fault의 심각성 💢

> Page Fault는 가상 메모리 시스템에서 불가피하게 발생. But **발생 빈도가 높으면 성능에 치명적**

 가상 메모리 기법은 RAM뿐만 아니라 HDD를 쓴다고 했었다.
 Page Fault 발생 시 HDD에서 페이지를 가져오는 과정은 아래와 같다.
 1. *Page-Out*
	 - 초기에는 RAM을 쓰다가 RAM이 꽉 차면 현재 잘 안쓰는 애플리케이션들을 HDD에 매핑 시킴
	   
 2. *Page-In*
	 - 필요한 데이터가 RAM이 아닌 HDD에 있다면 다시 주 기억장치인 RAM으로 가져와야 함
	 - 이 과정이 Page-in


> [!WARNING] 자주 발생된다면 아래와 같은 문제가 발생 
> 1. *디스크 접근이 많아져 성능 저하를 발생*시킨다
> 2. *다른 프로세스도 영향 받음*
> 	- 디스크 I/O는 엄청 느린데 **공용 자원이라, 다른 프로세스도 영향 받음**
> 	- 이로 인해, 시스템 **전체의 병목**이 발생 ➡ 시스템 전체 응답 성능이 떨어짐


#### 어떻게 해결?
#OS가_처리  #페지이교체정책 

> Page Fault 라는 H/W 인터럽트를 알리면 **OS가 이를 해결**한다 By **페이지 교체 정책**✅

(완전한 해결은 아니더라도 **최대한 Page Fault 비용**을 줄이는)


*✅페이지 교체 정책 흐름(Page Replacement)*
1. *어떤 페이지를 내보낼 지 결정*
	- RAM에서 **어떤 페이지를 내보낼지**를 선택
	- 보통 가장 최근에 사용하지 않은 페이지를 쫓아냄(완전한 방식은 아님)
	  
2. *디스크에 다시 쓸지 말지 판단 - Dirty? Clean?*
	1. *만약 페이지가 Dirty 하다면* 
		- OS는 그것을 **다시 디스크에 쓴다**
		- Dirty : 디스크에서 로드한 페이지가 수정되어 있을 경우 더럽다고 표현 
		  
	2. *만약 페이지가 Clean하다면* 
		- OS에 새로 저장할 필요가 없다(약간의 성능 향상)⭐
		- 그냥 수정 없이 교체만 하면 됨 
		  
3. *DMA를 활용한 전송⭐*
	- CPU가 데이터를 직접 복사하지 않고 CPU내의 **DMA(Direct Memory Access)가 디스크 ↔ RAM간 전송을 맡음** 
	- CPU는 **페이지 교체 동안 다른 작업 가능** ➡ **CPU 활용률 극대화** 


### 단일 메모리 접근의 한계
>[!EXAMPLE] 참고 : 페이지 테이블은 RAM에 저장되어 있음

#### 1. 비싼 램 접근 비용 - 2번 접근 必
![Pasted image 20250819151251.png](/img/user/supporter/image/Pasted%20image%2020250819151251.png)
- 가상 주소만 갖고 있는 CPU는 RAM에 2번 접근이 필요하다 
	1. 페이지 테이블에 해당 **가상 주소가 몇 번 물리 주소에 해당하는지 정보 얻기** 必 
	2. 그렇게 얻은 정보를 바탕으로 **RAM의 물리 주소에 접근 必**
	   
- 정리 : 물리 위치 찾기 위해 + 실제 물리 위치 접근 

#### 2. 공간 낭비 
- **프로세스별 Page Table을 생성**해 놓으면 엄청난 **공간 낭비**가 생긴다.
- 실제 프로세스가 **모든 Page Table 공간을 쓰지 않기에 심한 낭비** 발생 💢

> 이를 해결하고자 TLB or MLT(Multy Level Table) 방법이 생김 

## 단일 메모리 단점 해결 방안 1 - TLB

*등장 배경 = 위의 단일 메모리 접근의 한계*

### TLB란?
Translation Lookaside Buffer
#주소변환캐시 

참고 : [What is VM](https://www.youtube.com/watch?v=A9WLYbE0p-I&t=866s)

> 최근에 쓴 VA->PA **변환 결과를 캐시**하는 역할 

![Pasted image 20250819145041.png](/img/user/supporter/image/Pasted%20image%2020250819145041.png)
- *CPU에 추가된 특별한 구성요소* ➡ 고속 H/W 캐시 
	- 현대 CPU는 보통 2개의 TLB 가짐 
	- 하나는 ITLB : **명령어를 위한 것**
	- 다른 하나는 DTLB : **데이터를 위한 것**
	  
- *가상 주소에서 물리 주소의 **변환을 캐시**하는 역할*
	- ✅RAM으로의 **반복적인 접근을 줄여줌** + CPU에 있기 때문에 **매~우 빠름**
	- 💢약 4000 엔트리 정도만 가질 정도로 작다 (현대 CPU 아키텍쳐 기준)
		- 이로 인해 자주 업데이트 됨 
		- 성능 걱정 될 수 있지만 지역성 원리 잘 활용해서 ㄱㅊ ㄱㅊ 
	- 용량이 매우 적지만 **지역성 원리를 잘만 활용한다면 엄청난 성능 개선 가능** 

- *연관 메모리 방식이다*
	- ✅순차적으로 페이지를 찾는게 아니라 병렬 검색 
		![Pasted image 20250819151722.png](/img/user/supporter/image/Pasted%20image%2020250819151722.png)
		- 페이지 번호를 저장해 놓은 TLB 메모리를 동시에 확인 
		- 만약 이에 대응하는 Frame 번호가 TLB내에 있다면 바로 물리적 메모리 접근 가능
		  
	- 💢대신 **비용이 많이 듬**
		- 이렇게 고급 기능은 비쌈 
		- 그래서 많은 용량을 담을 수 없음 
		

### TLB Hit vs TLB Miss

1. *TLB Hit* 
	- TLB에서 Page번호와 대응하는 Frame 번호를 찾았을 경우 
	- 그냥 그 대응하는 Frame 번호를 바탕으로 물리 메모리 접근하면 끝 
	  
2. *TLB Miss*
	- TLB에서 Page번호와 대응하는 Frame 번호를 못❗ 찾았을 경우 
	- **교체 작업 必** By 교체 알고리즘 사용 
	- 흔한 교체 알고리즘 예시
		1. TLB 중 가장 **최근에 사용하지 않은 페이지를 삭제**
		2. RAM의 Page Table로부터 **원하는 페이지 정보 로드 必**(Page Table에도 없다면 실제 메모리에 접근 必)


>[!TIP] **지역성을 잘 활용해야** 함
>- TLB는 접근 횟수를 줄여주는 **성능의 핵심**
>- 근데 크기가 매우 작아(용량의 제한) **효율적으로 공간을 써야**한다
>	1. 💢*TLB miss가 자주 발생한다면*(ex. 임의 접근)
>		- TLB 페이지가 자주 교체되는 **비용 발생 ㅠ** 
>		- 이 때는, 오히려 TLB 사용하는 것이 **더 느릴 수 있음** 
>	2. ✅*TLB Hit가 자주 발생한다면❓* (ex. 반복 접근, 순차 접근)
>		- **성능 극대화 가능**
>		  
>- 효율적으로 공간을 쓰기 위해 중요한 것이 지역성 원리 활용해서 코드를 짜는 것 


> [!INFO] Context Switching 시 TLB 캐시는 사라진다.
> - 새로운 프로세스를 위해 TLB를 초기화 시킴 

### TLB와 메모리 접근 과정 
참고 : [TLB 페이징](https://www.youtube.com/watch?v=5goAc3cXWS4)

![Pasted image 20250819152632.png](/img/user/supporter/image/Pasted%20image%2020250819152632.png)

 

### 추가 : TLB Hit 율 높이는 방법
> 동일 페이지 연속 Hit 시 ➡ Page Table 접근할 필요 없어짐 ➡ 성능 향상 

#### 방법 1. TLB 항목 수를 늘리기 

✅장점 
- 아주 간단한 방법.

💢단점 
- 💢대신 비용이 많이 듦  

#### 방법 2. TLB 내 페이지 크기 늘리기 

✅장점 
- 더 많은 물리 주소를 담을 수 있어진다 ➡ 성능 향상 

💢단점 
- **내부 단편화** 발생 ➡ **메모리 낭비**


> 이런 방법들을 적절하게 사용할 수 있게 해주는 기준 = TLB 도달 범위  <<< 필요하면 공부 ㄱ 


### TLB의 한계 

여전히 TLB에 로드되어도 디스크에 있는 페이지 접근 요청 시 Page Fault는 발생한다



## 단일 메모리 단점 해결 방안 2 - MPT
MPT = Multi-level Page Tables 


