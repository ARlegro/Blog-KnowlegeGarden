---
{"dg-publish":true,"permalink":"/DevStudy/AI/AI Agent 기본 원리/","noteIcon":"","created":"2025-12-13T18:27:34.894+09:00","updated":"2025-12-13T19:56:48.176+09:00"}
---




## 1.  AI Agent란?


### 1.1.  개념 

>[!question] agent란❓
>- 언어 모델을 활용해 일련의 행동을 스스로 선택하게 만드는 것
>- Agent는 추론 엔진을 통해 어떤 행동을 할지, 어떤 순서로 진행할지를 스스로 결정
>- 기본 3요소
>	1. 계획
>	2. 기억
>	3. 도구 활용



Agent는 
- 스스로 계획하고
- 기억을 활용하고
- 도구를 선택해서 문제 해결하는  

지능형 실행 시스템



### 1.2.  구조
>[!tip] AI Agent는 감지·사고·행동·피드백이 분리된 구조적 시스템<br>

- *감지(Sense)* : 상황/세상을 관찰해 의사결정 재료를 만듬
- *사고(Think)* : 목표와 제약을 고려해 **무엇을 할지** 결정
- *행동(Act)* : 실제 세계(시스템)에 변화를 만듬
- *피드백(Feedback)* : 행동 결과를 평가해 다음 판단에 반영


### 1.3.  vs 단순 LLM

| 비교       | 방식                            |
| -------- | ----------------------------- |
| 단순 LLM   | 입력 → 출력                       |
| AI Agent | 입력 → **고려 → 판단 → 계획 → 실행 결정** |
- 단순 LLM 기반 챗봇은 질문에 반응할 뿐이지만 
- AI Agent는 목표를 기준으로 스스로 다음 행동을 결정한다
- AI Agent = 감지 ➡ 사고 ➡ 행동 ➡ 피드백 루프

### 1.4.  왜 필요한가

LLM을 단순 “질문 → 답변” 생성기로 쓰면 할 수 있는 일이 제한된다. **실제 문제 해결 시스템**으로 만들려면 LLM이 아래 역할을 할 수 있어야 한다.
- 정보를 **기억**하고
- 필요한 작업을 여러 단계로 나누고 **스스로 결정**하고
- DB/검색/내부 API 같은 **외부 도구를 호출**하고
- **이전 결과를 기반**으로 다음 행동을 선택해야 함 

**이것들을 가능하게 하는 구조 ➡ Agent ⭐⭐**


## 2.  감지(Sense) 단계

> Agent가 결정을 내리기 전에 세상을 인식하는 단계

상황을 인식하지 않는 Agent는 그냥 반응만 하는 "자동 응답기"

### 2.1.  감지의 유형 
어떻게 감지하는가?
1. *Text*
	- 챗봇, AI 비서의 가장 기본 형태
	- 자연어 입력 처리
2. *센서(Sensor)*
	- 카메라 (시각)
	- 마이크 (청각)
	- GPS, 가속도 센서 등
	  
3. *시스템/이벤트 입력*
	- API
	- DB 이벤트
	- 외부 시스템 알림

### 2.2.  감지 단계의 본질 
> ❌판단<br>
> ✅관찰

>[!tip] 
>Sens는 "의사결정의 재료"를 만드는 단계(판단 거의 없음)
>- 데이터 해석이 없음
>- 의미 부여 X
>- 단순히 Think 계층에 전달할 뿐 

## 3.  Think 단계 - 핵심

### 3.1.  필요한 이유
>[!QUESTION] 인식을 하고나면 어떻게 처리할까❓
>이러한 질문에 Context가 필요하다는 것이 밝혀짐 ➡ Knowlege 소스가 필요 (지식 기반)


Agent는 “무엇을 할지”를 **즉시 말하지 않는다**.  
대신 다음을 먼저 고려한다:

- 지금 상황은 무엇인가?
- 목표는 무엇인가?
- 제한 조건은 무엇인가?
- 지금 행동하는 게 맞는가?

### 3.2.  구성 요소들

> Think 계층에는 **지식 기반(Knowledge Base)** 이 결합된다.

핵심 지식의 종류
- *Facts*
	- 사실
	- 시스템 상태, 사용자 정보, 현재 데이터 
- *Rules*
	- 시스템에 고려해야할 규칙
	- 목표, 제약 조건
	- 우선순위 등 
- *Context*
	- 현재 대화 흐름
	- 이전 행동 이력 
- *정책 정보*
	- 시스템이 추구하는 목표 
	- 우선순위 
	- 상황에 따라 고려해야 할 목표



이러한 지식들은 Agent의 사고 과정(Thinking Process)에 들어갈 것 <br>
지식의 출처는 다양
- *DB*에서 올 수도 있고 
- *RAG*소스 기반일 수도 있다.
- *외부 API*일수도

**이러한 모든 지식들은 Think 계층에서 종합적으로 고려된다.**

### 3.3.  추론(Reasoning) 

> 의사결정 단계 - 모든 정보(지식, 문맥, 정책 등)를 종합해 무엇을 할지 결정

에이전트는 지식들을 갖고 바로 Act하지 않는다. 
- 여러 지식간의 충돌을 해결하거나
- 목표 대비 최적의 행동을 선택하거나
- 지금 바로 ACT를 해야하는지 판단 한다.



### 3.4.  계획 수립 & 작업 분해 (Task Decomposition)

> Agent가 수행해야 하는 큰 목표를 바로 수행할 수 없기에 "**계획 수립**"과 "**작업 분해**"과정을 겪음

- 복잡한 문제를 실행 가능한 단위로 쪼개고
- 각 단계의 성공/실패를 개별적으로 판단 가능하게 함 

예시 - 출장 예약
1. 날짜 확인
2. 목적지 확인
3. 항공편 확인
4. 호텔 필터링
5. 정책 검증
6. 예약 실행



### 3.5.  학습 요소의 결합(ML / RL)

>[!CHECK] 정적인 Think로직의 한계 돌파 ➡ ML / RL 

>  ML과 RL을 결합하여 AI 시스템의 Think 계층을 구축할 수 있다.

1. *ML(Machine Learing) = 기계 학습, 패턴 학습* 
	- **과거 데이터 기반 패턴 학습** 
	- 분류, 예측, 추천 등에서 쓰임 
	- *원리*
		- AI가 **방대한 양의 데이터**를 분석하여 데이터 속에 숨겨진 **규칙, 관계, 특징**을 자동으로 찾아냄
		- 특정 상황에서 보통 어떤 선택을 하는지 보고 파난

2. *RL(Reinforcement Learning) = 강화 학습*
	- 시행 착오를 통해 학습하는 방식 
		- 시스템(에이전트)이 **환경**과 상호작용하며 **보상**을 최대화하는 방향으로 행동을 학습
		- "행동 → 결과 → 보상"을 통해 **더 좋은 판단 전략을 학습**
	- *원리*
		- AI는 특정 환경에서 행동을 취하면 그 결과를 받고 보상 or 벌칙을 받음
		- 장기적으로 가장 높은 보상을 얻을 수 잇는 판단 전략을 학습하게 됨 
		- 명확한 정답보다는 '잘했는지/못했는지'에 대한 피드백을 받음

### 3.6.  LLM의 역할
> 사고 계층에서 LLM은 언어적 추론 엔진 역할을 함 

- 자연어 이해
- 추론 흐름 유지
- 계획 텍스트화
- 조건 판단 지원


## 4.  행동 단계

> 사고가 끝나면 결과 실행 必

### 4.1.  행동의 유형 

1. *출력* 
	- 텍스트, 음성, 알림, 비디오
	  
2. *시스템 액션*
	- DB 읽기/쓰기
	- API 호출
	- 이벤트 발생 
	  
3. *물리적 행동* 
	- 차량 제어
	- 장비 제어 

## 5.  피드백 루프 단계
에이전트를 똑똑하게 만드는 핵심 

> 시스템은 행동을 시도하고 그것이 목표에 더 가까워졌는지 멀어졌는지 확인하며 자체 피드백을 얻음 




### 5.1.  그렇다면 LangChain / LangGraph도❓

>[!danger] LangChain, LangGraph는 피드백을 반영하는 시스템이 아니다
>단지 추론과 실행을 연결해주는 프레임워크이지 학습하고 강화하는 시스템이 아님